"use strict";(self.webpackChunkzen=self.webpackChunkzen||[]).push([[3708],{3905:function(n,e,i){i.d(e,{Zo:function(){return c},kt:function(){return u}});var t=i(7294);function a(n,e,i){return e in n?Object.defineProperty(n,e,{value:i,enumerable:!0,configurable:!0,writable:!0}):n[e]=i,n}function r(n,e){var i=Object.keys(n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(n);e&&(t=t.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),i.push.apply(i,t)}return i}function o(n){for(var e=1;e<arguments.length;e++){var i=null!=arguments[e]?arguments[e]:{};e%2?r(Object(i),!0).forEach((function(e){a(n,e,i[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(i)):r(Object(i)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(i,e))}))}return n}function m(n,e){if(null==n)return{};var i,t,a=function(n,e){if(null==n)return{};var i,t,a={},r=Object.keys(n);for(t=0;t<r.length;t++)i=r[t],e.indexOf(i)>=0||(a[i]=n[i]);return a}(n,e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);for(t=0;t<r.length;t++)i=r[t],e.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(n,i)&&(a[i]=n[i])}return a}var l=t.createContext({}),s=function(n){var e=t.useContext(l),i=e;return n&&(i="function"==typeof n?n(e):o(o({},e),n)),i},c=function(n){var e=s(n.components);return t.createElement(l.Provider,{value:e},n.children)},p={inlineCode:"code",wrapper:function(n){var e=n.children;return t.createElement(t.Fragment,{},e)}},g=t.forwardRef((function(n,e){var i=n.components,a=n.mdxType,r=n.originalType,l=n.parentName,c=m(n,["components","mdxType","originalType","parentName"]),g=s(i),u=a,d=g["".concat(l,".").concat(u)]||g[u]||p[u]||r;return i?t.createElement(d,o(o({ref:e},c),{},{components:i})):t.createElement(d,o({ref:e},c))}));function u(n,e){var i=arguments,a=e&&e.mdxType;if("string"==typeof n||a){var r=i.length,o=new Array(r);o[0]=g;var m={};for(var l in e)hasOwnProperty.call(e,l)&&(m[l]=e[l]);m.originalType=n,m.mdxType="string"==typeof n?n:a,o[1]=m;for(var s=2;s<r;s++)o[s]=i[s];return t.createElement.apply(null,o)}return t.createElement.apply(null,i)}g.displayName="MDXCreateElement"},2476:function(n,e,i){i.r(e),i.d(e,{assets:function(){return p},contentTitle:function(){return s},default:function(){return d},frontMatter:function(){return l},metadata:function(){return c},toc:function(){return g}});var t=i(3117),a=i(102),r=(i(7294),i(3905)),o=i(4996),m=["components"],l={title:"Spatial Domain",sidebar_label:"Spatial Domain"},s=void 0,c={unversionedId:"dip/spatial-domain",id:"dip/spatial-domain",title:"Spatial Domain",description:"Point-Processing Techniques",source:"@site/docs/dip/spatial-domain.mdx",sourceDirName:"dip",slug:"/dip/spatial-domain",permalink:"/zen/dip/spatial-domain",editUrl:"https://github.com/vamsi3/zen/edit/master/docs/dip/spatial-domain.mdx",tags:[],version:"current",lastUpdatedAt:1657897032,formattedLastUpdatedAt:"7/15/2022",frontMatter:{title:"Spatial Domain",sidebar_label:"Spatial Domain"},sidebar:"dip",previous:{title:"Home",permalink:"/zen/dip"}},p={},g=[{value:"Point-Processing Techniques",id:"point-processing-techniques",level:2},{value:"Gamma Correction",id:"gamma-correction",level:3},{value:"Piecewise Linear Transformations",id:"piecewise-linear-transformations",level:3},{value:"Contrast Stretching",id:"contrast-stretching",level:4},{value:"Intensity-Level Slicing",id:"intensity-level-slicing",level:4},{value:"Bit-Plane Slicing",id:"bit-plane-slicing",level:4},{value:"Histogram Processing",id:"histogram-processing",level:3},{value:"Histogram Equalization",id:"histogram-equalization",level:4}],u={toc:g};function d(n){var e=n.components,i=(0,a.Z)(n,m);return(0,r.kt)("wrapper",(0,t.Z)({},u,i,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"point-processing-techniques"},"Point-Processing Techniques"),(0,r.kt)("p",null,"Operations applied directly on individual image pixel values independently."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"import cv2\nimport numpy as np\n\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255\n\nnegative_transformation = lambda x : 1 - x\nnegative_img = negative_transformation(img)\n\nlog_transformation = lambda x, k: np.log1p(k * x) / np.log1p(k) # k in (-1, inf) - {1}. k = 1 is limiting case of identity function\nlog_img = log_transformation(img, 100)\n\n# called power-law transformations or gamma transformations\ngamma_transformation = lambda x, gamma: np.power(x, gamma) # gamma in (0, inf). gamma = 1 is case of identity function\ngamma_img = gamma_transformation(img, 4)\n\nconcat_img = np.hstack((img, log_img)); cv2.imshow('1', concat_img); cv2.waitKey()\n")),(0,r.kt)("h3",{id:"gamma-correction"},"Gamma Correction"),(0,r.kt)("img",{src:(0,o.Z)("/dip/gamma-correction.png")}),(0,r.kt)("div",{align:"right"},(0,r.kt)("em",null,"Image Credits: Book by Gonzalez, Woods")),(0,r.kt)("h3",{id:"piecewise-linear-transformations"},"Piecewise Linear Transformations"),(0,r.kt)("h4",{id:"contrast-stretching"},"Contrast Stretching"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"import cv2\nimport numpy as np\n\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255\n\npiecewise_linear_transformation = lambda x, r1, s1, r2, s2 : np.piecewise(x, [x <= r1, x >= r2], [lambda x: s1 * x / r1, lambda x: 1 + (1 - s2) * (x - 1) / (1 - r2), lambda x : s1 + (s1 - s2) * (x - r1) / (r1 - r2)])\npiecewise_linear_img = piecewise_linear_transformation(img, img.mean(), 0, img.mean(), 1)\n")),(0,r.kt)("img",{src:(0,o.Z)("/dip/contrast-stretching.png")}),(0,r.kt)("div",{align:"right"},(0,r.kt)("em",null,"Image Credits: Book by Gonzalez, Woods")),(0,r.kt)("h4",{id:"intensity-level-slicing"},"Intensity-Level Slicing"),(0,r.kt)("img",{src:(0,o.Z)("/dip/intensity-level-slicing.png")}),(0,r.kt)("div",{align:"right"},(0,r.kt)("em",null,"Image Credits: Book by Gonzalez, Woods")),(0,r.kt)("h4",{id:"bit-plane-slicing"},"Bit-Plane Slicing"),(0,r.kt)("p",null,"This is useful for image compression, where we can just take bit planes 8, 7 (or 6, 5 etc. in some cases) and have sufficiently good detail."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # note that img.dtype is uint8\n\nbit_plane_slicing_img = np.unpackbits(img[np.newaxis], axis=0, bitorder='little').astype(np.float64)\n\n_, ax = plt.subplots(3, 3)\nax[0, 0].imshow(img / 255, cmap='gray', vmin=0, vmax=1)\nax[0, 1].imshow(bit_plane_slicing_img[7], cmap='gray', vmin=0, vmax=1)\nax[0, 2].imshow(bit_plane_slicing_img[6], cmap='gray', vmin=0, vmax=1)\nax[1, 0].imshow(bit_plane_slicing_img[5], cmap='gray', vmin=0, vmax=1)\nax[1, 1].imshow(bit_plane_slicing_img[4], cmap='gray', vmin=0, vmax=1)\nax[1, 2].imshow(bit_plane_slicing_img[3], cmap='gray', vmin=0, vmax=1)\nax[2, 0].imshow(bit_plane_slicing_img[2], cmap='gray', vmin=0, vmax=1)\nax[2, 1].imshow(bit_plane_slicing_img[1], cmap='gray', vmin=0, vmax=1)\nax[2, 2].imshow(bit_plane_slicing_img[0], cmap='gray', vmin=0, vmax=1)\nplt.show()\n")),(0,r.kt)("h3",{id:"histogram-processing"},"Histogram Processing"),(0,r.kt)("h4",{id:"histogram-equalization"},"Histogram Equalization"))}d.isMDXComponent=!0}}]);