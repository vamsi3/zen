"use strict";(self.webpackChunkzen=self.webpackChunkzen||[]).push([[3708],{9613:(e,i,n)=>{n.d(i,{Zo:()=>c,kt:()=>d});var t=n(9496);function a(e,i,n){return i in e?Object.defineProperty(e,i,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[i]=n,e}function r(e,i){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);i&&(t=t.filter((function(i){return Object.getOwnPropertyDescriptor(e,i).enumerable}))),n.push.apply(n,t)}return n}function o(e){for(var i=1;i<arguments.length;i++){var n=null!=arguments[i]?arguments[i]:{};i%2?r(Object(n),!0).forEach((function(i){a(e,i,n[i])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(i){Object.defineProperty(e,i,Object.getOwnPropertyDescriptor(n,i))}))}return e}function l(e,i){if(null==e)return{};var n,t,a=function(e,i){if(null==e)return{};var n,t,a={},r=Object.keys(e);for(t=0;t<r.length;t++)n=r[t],i.indexOf(n)>=0||(a[n]=e[n]);return a}(e,i);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)n=r[t],i.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var m=t.createContext({}),s=function(e){var i=t.useContext(m),n=i;return e&&(n="function"==typeof e?e(i):o(o({},i),e)),n},c=function(e){var i=s(e.components);return t.createElement(m.Provider,{value:i},e.children)},p={inlineCode:"code",wrapper:function(e){var i=e.children;return t.createElement(t.Fragment,{},i)}},g=t.forwardRef((function(e,i){var n=e.components,a=e.mdxType,r=e.originalType,m=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),g=s(n),d=a,v=g["".concat(m,".").concat(d)]||g[d]||p[d]||r;return n?t.createElement(v,o(o({ref:i},c),{},{components:n})):t.createElement(v,o({ref:i},c))}));function d(e,i){var n=arguments,a=i&&i.mdxType;if("string"==typeof e||a){var r=n.length,o=new Array(r);o[0]=g;var l={};for(var m in i)hasOwnProperty.call(i,m)&&(l[m]=i[m]);l.originalType=e,l.mdxType="string"==typeof e?e:a,o[1]=l;for(var s=2;s<r;s++)o[s]=n[s];return t.createElement.apply(null,o)}return t.createElement.apply(null,n)}g.displayName="MDXCreateElement"},2674:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>s,contentTitle:()=>l,default:()=>g,frontMatter:()=>o,metadata:()=>m,toc:()=>c});var t=n(4250),a=(n(9496),n(9613)),r=n(1661);const o={title:"Spatial Domain",sidebar_label:"Spatial Domain"},l=void 0,m={unversionedId:"dip/spatial-domain",id:"dip/spatial-domain",title:"Spatial Domain",description:"Point-Processing Techniques",source:"@site/docs/dip/spatial-domain.mdx",sourceDirName:"dip",slug:"/dip/spatial-domain",permalink:"/zen/dip/spatial-domain",draft:!1,editUrl:"https://github.com/vamsi3/zen/edit/master/docs/dip/spatial-domain.mdx",tags:[],version:"current",lastUpdatedAt:1667746530,formattedLastUpdatedAt:"Nov 6, 2022",frontMatter:{title:"Spatial Domain",sidebar_label:"Spatial Domain"},sidebar:"dip",previous:{title:"Home",permalink:"/zen/dip"}},s={},c=[{value:"Point-Processing Techniques",id:"point-processing-techniques",level:2},{value:"Gamma Correction",id:"gamma-correction",level:3},{value:"Piecewise Linear Transformations",id:"piecewise-linear-transformations",level:3},{value:"Contrast Stretching",id:"contrast-stretching",level:4},{value:"Intensity-Level Slicing",id:"intensity-level-slicing",level:4},{value:"Bit-Plane Slicing",id:"bit-plane-slicing",level:4},{value:"Histogram Processing",id:"histogram-processing",level:3},{value:"Histogram Equalization",id:"histogram-equalization",level:4}],p={toc:c};function g(e){let{components:i,...n}=e;return(0,a.kt)("wrapper",(0,t.Z)({},p,n,{components:i,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"point-processing-techniques"},"Point-Processing Techniques"),(0,a.kt)("p",null,"Operations applied directly on individual image pixel values independently."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"import cv2\nimport numpy as np\n\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255\n\nnegative_transformation = lambda x : 1 - x\nnegative_img = negative_transformation(img)\n\nlog_transformation = lambda x, k: np.log1p(k * x) / np.log1p(k) # k in (-1, inf) - {1}. k = 1 is limiting case of identity function\nlog_img = log_transformation(img, 100)\n\n# called power-law transformations or gamma transformations\ngamma_transformation = lambda x, gamma: np.power(x, gamma) # gamma in (0, inf). gamma = 1 is case of identity function\ngamma_img = gamma_transformation(img, 4)\n\nconcat_img = np.hstack((img, log_img)); cv2.imshow('1', concat_img); cv2.waitKey()\n")),(0,a.kt)("h3",{id:"gamma-correction"},"Gamma Correction"),(0,a.kt)("img",{src:(0,r.Z)("/dip/gamma-correction.png")}),(0,a.kt)("div",{align:"right"},(0,a.kt)("em",null,"Image Credits: Book by Gonzalez, Woods")),(0,a.kt)("h3",{id:"piecewise-linear-transformations"},"Piecewise Linear Transformations"),(0,a.kt)("h4",{id:"contrast-stretching"},"Contrast Stretching"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"import cv2\nimport numpy as np\n\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) / 255\n\npiecewise_linear_transformation = lambda x, r1, s1, r2, s2 : np.piecewise(x, [x <= r1, x >= r2], [lambda x: s1 * x / r1, lambda x: 1 + (1 - s2) * (x - 1) / (1 - r2), lambda x : s1 + (s1 - s2) * (x - r1) / (r1 - r2)])\npiecewise_linear_img = piecewise_linear_transformation(img, img.mean(), 0, img.mean(), 1)\n")),(0,a.kt)("img",{src:(0,r.Z)("/dip/contrast-stretching.png")}),(0,a.kt)("div",{align:"right"},(0,a.kt)("em",null,"Image Credits: Book by Gonzalez, Woods")),(0,a.kt)("h4",{id:"intensity-level-slicing"},"Intensity-Level Slicing"),(0,a.kt)("img",{src:(0,r.Z)("/dip/intensity-level-slicing.png")}),(0,a.kt)("div",{align:"right"},(0,a.kt)("em",null,"Image Credits: Book by Gonzalez, Woods")),(0,a.kt)("h4",{id:"bit-plane-slicing"},"Bit-Plane Slicing"),(0,a.kt)("p",null,"This is useful for image compression, where we can just take bit planes 8, 7 (or 6, 5 etc. in some cases) and have sufficiently good detail."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('lena.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # note that img.dtype is uint8\n\nbit_plane_slicing_img = np.unpackbits(img[np.newaxis], axis=0, bitorder='little').astype(np.float64)\n\n_, ax = plt.subplots(3, 3)\nax[0, 0].imshow(img / 255, cmap='gray', vmin=0, vmax=1)\nax[0, 1].imshow(bit_plane_slicing_img[7], cmap='gray', vmin=0, vmax=1)\nax[0, 2].imshow(bit_plane_slicing_img[6], cmap='gray', vmin=0, vmax=1)\nax[1, 0].imshow(bit_plane_slicing_img[5], cmap='gray', vmin=0, vmax=1)\nax[1, 1].imshow(bit_plane_slicing_img[4], cmap='gray', vmin=0, vmax=1)\nax[1, 2].imshow(bit_plane_slicing_img[3], cmap='gray', vmin=0, vmax=1)\nax[2, 0].imshow(bit_plane_slicing_img[2], cmap='gray', vmin=0, vmax=1)\nax[2, 1].imshow(bit_plane_slicing_img[1], cmap='gray', vmin=0, vmax=1)\nax[2, 2].imshow(bit_plane_slicing_img[0], cmap='gray', vmin=0, vmax=1)\nplt.show()\n")),(0,a.kt)("h3",{id:"histogram-processing"},"Histogram Processing"),(0,a.kt)("h4",{id:"histogram-equalization"},"Histogram Equalization"))}g.isMDXComponent=!0}}]);